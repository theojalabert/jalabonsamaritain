dexp(3,1/params$d)
dexp(0.00082,1/params$d)
rvol<- function(n,params){
c <- 1/(params$d*(exp(-params$a/params$d)*(1-params$alpha/(1+((2*pi*params$d)/params$sigma)**2))-exp(-params$b/params$d)*(1+(params$alpha/(1+((2*pi*params$d)/params$sigma)**2))*(((2*pi*params$d)/params$sigma)*sin(((2*pi*(params$b-params$a))/params$sigma))-cos(((2*pi*(params$b-params$a))/params$sigma))))))
f_e <- function(u,params){
if (u < params$a) return(0)
if (u > params$b) return(0)
else{
return(c*exp(-u/params$d)*(1-(params$alpha*cos(2*pi*((u-params$a)/params$sigma)))))
}
}
M <- c*params$d*(1+params$alpha)
X <- numeric(n)
i<-0
while (i < n){
E <- rexp(1,rate=1/params$d)
U <- runif(1,min=0,max=M)
if (U<=((f_e(E,params))/(dexp(E,1/params$d)))){
i <- i+1
X[i] = E
}
}
return (X)
}
rvol(10**5,params)
mean(rvol(10**5,params))
mean(rvol(10**5,params))
sd(rvol(10**5,params))
help("sapply")
esp.t(100,params)
esp.t <- function(n.simul,params){
sim1_T<-function(n,lambda){
i = 0
T = 0
while(i < n){
E <- rexp(1,lambda)
U<-runif(1,0,1)
if (U<=((lambda*(1+sin((T-(1/4)))))/(2*lambda))){
i <- i+1
T <- T + E
}
}
return (T)
}
simul_T <- function(params){
Vdebite = 0
i = 0
while(Vdebite < params$V){
Vdebite = Vdebite + rvol(1,params)
i = i + 1
}
return (sim1_T(i,params$lambda))
}
#esperance <- sapply(numeric(n.simul),function(a,b,d,alpha,sigma,lambda,V) simul_T(params))
esperance <- sapply(numeric(n.simul),function(V,lambda,a,b,d,alpha,sigma) simul_T(params))
return(list(esp = mean(esperance),sigma = sd(esperance)))
}
## PROBABILITÉ DE PÉNURIE
pzero <- function(n.simul,params){
sim1_T<-function(n,lambda){
i = 0
T = 0
while(i < n){
E <- rexp(1,lambda)
U <- runif(1,0,1)
if (U<=((lambda*(1+sin((T-(1/4)))))/(2*lambda))){
i <- i+1
T <- T + E}
}
return (T)}
simul_T <- function(params){
Vdebite = 0
i = 0
while(Vdebite < params$V){
Vdebite = Vdebite + rvol(1,params)
i = i + 1 }
return (sim1_T(i,params$lambda)) }
list_pz <- numeric(n.simul)
for (i in 1:n.simul){
list_t <- numeric(n.simul)
for (j in 1:n.simul){
list_t[j] = as.integer(simul_T(params)<params$T)
}
list_pz[i] = mean(list_t)
}
pzero = mean(list_pz)
demi = qnorm(0.975)*sd(list_pz)/sqrt(n.simul)
return(list(p=pzero,demi.largeur=demi))
}
esp.t(100,params)
## CODE PROJET SIMULATION GROUPE 11 - JALABERT/BERTRANET/SIMONEAU-FRIGGI/KHORSI
## SIMULATION DE LA LOI P_E
rvol<- function(n,params){
c <- 1/(params$d*(exp(-params$a/params$d)*(1-params$alpha/(1+((2*pi*params$d)/params$sigma)**2))-exp(-params$b/params$d)*(1+(params$alpha/(1+((2*pi*params$d)/params$sigma)**2))*(((2*pi*params$d)/params$sigma)*sin(((2*pi*(params$b-params$a))/params$sigma))-cos(((2*pi*(params$b-params$a))/params$sigma))))))
f_e <- function(u,params){
if (u < params$a) return(0)
if (u > params$b) return(0)
else{
return(c*exp(-u/params$d)*(1-(params$alpha*cos(2*pi*((u-params$a)/params$sigma)))))
}
}
M <- c*params$d*(1+params$alpha)
X <- numeric(n)
i<-0
while (i < n){
E <- rexp(1,rate=1/params$d)
U <- runif(1,min=0,max=M)
if (U<=((f_e(E,params))/(dexp(E,1/params$d)))){
i <- i+1
X[i] = E
}
}
return (X)
}
## ESPÉRANCE DE T
esp.t <- function(n.simul,params){
sim1_T<-function(n,lambda){
i = 0
T = 0
while(i < n){
E <- rexp(1,lambda)
U<-runif(1,0,1)
if (U<=((lambda*(1+sin((T-(1/4)))))/(2*lambda))){
i <- i+1
T <- T + E
}
}
return (T)
}
simul_T <- function(params){
Vdebite = 0
i = 0
while(Vdebite < params$V){
Vdebite = Vdebite + rvol(1,params)
i = i + 1
}
return (sim1_T(i,params$lambda))
}
#esperance <- sapply(numeric(n.simul),function(a,b,d,alpha,sigma,lambda,V) simul_T(params))
espt <- sapply(numeric(n.simul),function(V,lambda,a,b,d,alpha,sigma) simul_T(params))
return(list(esp = mean(espt),sigma = sd(espt)))
}
esp.t(100,params)
esp.t(100,params)
A <- c(1,-2,9,8,-5,4)
Bool <- (A < 0)
A
Bool
as.integer(Bool)
## GROUPE 11 JALABERT SABRINA BERTRANET SIMONEAU-FRIGGI
params<-list(60000,2000,1.27,1,330,23,12,1)
params<-as.data.frame(params)
colnames(params)=c("V","lambda","T","a","b","d","alpha","sigma")
n=10**8
## SIMULATION DE Pe
rvol<- function(n,params){
c <- 1/(params$d*(exp(-params$a/params$d)*(1-params$alpha/(1+((2*pi*params$d)/params$sigma)**2))-exp(-params$b/params$d)*(1+(params$alpha/(1+((2*pi*params$d)/params$sigma)**2))*(((2*pi*params$d)/params$sigma)*sin(((2*pi*(params$b-params$a))/params$sigma))-cos(((2*pi*(params$b-params$a))/params$sigma))))))
f_e <- function(u,params){
if (u < params$a) return(0)
if (u > params$b) return(0)
else{
return(c*exp(-u/params$d)*(1-(params$alpha*cos(2*pi*((u-params$a)/params$sigma)))))
}
}
h <- function(u,params){
return(exp(-u/params$d)/params$d)
}
e<-((1+params$alpha)*c)/params$d
X <- numeric(n)
i<-0
while (i<n){
Y <- rexp(1,rate=1/params$d)
U <- runif(1,min=0,max=e)
if (U<=((f_e(Y,params))/(e*h(Y,params)))){
i<-i+1
X[i] = Y
}
}
return (X)
}
##APPROXIMATION DE L'ESPERANCE
simul_temps_arret<-function(lam,n){
K=0
t=0
while(K<n){
expo<- rexp(1,lam)
U<-runif(1,0,1)
if (U<=((lam*(1+sin((t-(1/4)))))/(2*lam))){
K <- K+1
t <- t+expo
}
}
t
}
simul_arret_station <- function(params){
Vdebit = 0
K = 0
while(Vdebit< params$V){
Vdebit = Vdebit + rvol(1,params)
K = K + 1
}
return (simul_temps_arret(params$lambda,K))
}
esp.t<-function(n.simul,params){
esperance <- sapply(numeric(n.simul),function(a,b,d,alpha,sigma,lambda,V) simul_arret_station(params))
return(list(esp = mean(esperance),sigma = sd(esperance)))
}
##APPROXIMATION DE LA PROBABILITE P0
pzero_sim1 <- function(n.simul,params){
S_esp_ind <- c()
for (i in 1:n.simul){
t <- simul_arret_station(params)
#print(t)
if (t < params$T){
S_esp_ind <- append(S_esp_ind,1)
}
else {S_esp_ind <- append(S_esp_ind,0)}
}
#print(S_esp_ind)
p <- mean(S_esp_ind)
#print(p)
return (p)
}
pzero <- function(n.simul,params){
p_list <- c()
for (i in 1:n.simul){
p_list <- append(p_list,pzero_sim1(n.simul,params))
}
proba <- mean(p_list)
demi <- qnorm(0.975)*sd(p_list)/sqrt(n.simul)
return (list(p=proba,demi.largeur=demi))
}
#####REDUCTION DE VARIANCE#####
#Simuler un vecteur de temps d'arr?t avec rvol
liste_T <- function(n.simul,params){
L_T <- numeric(n.simul)
for (i in 1:n.simul){ L_T[i] = simul_arret_station(params)}
return (L_T)
}
#Simuler un vecteur de temps d'arr?t avec loi normale
simul_arret_station_red <- function(n.simul,params){
Vdebit = 0
K = 0
m = mean(rvol(n.simul,params))
s = sqrt(var(rvol(n.simul,params)))
while (Vdebit < params$V){
Vdebit = Vdebit + sqrt(rnorm(1,m,s)**2)
K <- K+1
}
return (simul_temps_arret(params$lambda,K))
}
liste_T_red <- function(n.simul,params){
L_T_red <- numeric(n.simul)
for (i in 1:n.simul){ L_T_red[i] = simul_arret_station_red(n.simul,params)}
return (L_T_red)
}
#Esperance de l'indicatrice(T<T1)
esp_rvol<-function(n.simul,params){
Liste_temps_rvol<-liste_T(n.simul,params)
Ind_rvol<-as.integer(Liste_temps_rvol < params$T)
E_ind_rvol<-mean(Ind_rvol)
return(E_ind_rvol)
}
#Esperance de l'indicatrice(T'<T1)
esp_norm<-function(n.simul,params){
Liste_temps_norm<-liste_T_red(n.simul,params)
Ind_norm<-as.integer(Liste_temps_norm < params$T)
E_ind_norm<-mean(Ind_norm)
return(E_ind_norm)
}
Reduction_variance<-function(n.simul,params){
Liste_temps_rvol<-liste_T(n.simul,params)
Ind_rvol<-as.integer(Liste_temps_rvol < params$T)
E_ind_rvol<-mean(Ind_rvol)
Liste_temps_norm<-liste_T_red(n.simul,params)
Ind_norm<-as.integer(Liste_temps_norm < params$T)
E_ind_norm<-mean(Ind_norm)
k=cov(Ind_rvol,Ind_norm)/var(Ind_norm)
print(E_ind_rvol)
print(E_ind_norm)
print(k)
VEC<-Ind_rvol- k*Ind_norm
Esperance<-mean(VEC)-k*E_ind_norm
return(Esperance)
}
Reduction_variance(10,params)
Reduction_variance<-function(n.simul,params){
Liste_temps_rvol<-liste_T(n.simul,params)
Ind_rvol<-as.integer(Liste_temps_rvol < params$T)
E_ind_rvol<-mean(Ind_rvol)
Liste_temps_norm<-liste_T_red(n.simul,params)
Ind_norm<-as.integer(Liste_temps_norm < params$T)
E_ind_norm<-mean(Ind_norm)
k=cov(Ind_rvol,Ind_norm)/var(Ind_norm)
VEC<-Ind_rvol- k*Ind_norm
Esperance<-mean(VEC)-k*E_ind_norm
return(Esperance)
}
Reduction_variance(10,params)
Reduction_variance(10,params)
Reduction_variance(10,params)
Reduction_variance(10,params)
Reduction_variance(100,params)
Reduction_variance(100,params)
Reduction_variance(100,params)
dexp(0.8,2)
dexp(0.8,2)
dexp(0.8,9)
pzero.c <- function(n.simul,params){
library(Rcpp)
cppFunction("double sim1(int n, double lambda){
int i = 0;
double T = 0;
while (i<n)
{
double E = as<double>(Rcpp::rexp(1,lambda));
double U = as<double>(Rcpp::runif(1,0,1));
if (U <= (1+sin(((T-(1/4))))/2))
{
i++;
T = T + E;
}
}
return(T);
}")
cppFunction("double simulT(DataFrame params, Function rvol, Function sim1){
double V = params[0];
double lambda = params[2];
double Vdebite = 0;
int i = 0;
while (Vdebite < V)
{
Vdebite = Vdebite + as<double>(rvol(1,params));
i++;
}
return(as<double>(sim1(i,lambda)));
}")
cppFunction("List PZ(int n, DataFrame params, Function rvol, Function sim1, Function simulT){
double T = params[1];
Rcpp::List list_pz(n);
for (int i=0;i<n;i++)
{
double S = 0;
for (int j=0;j<n;j++)
{
S = S + int(as<double>(simulT(params,rvol,sim1)) < T);
}
list_pz[i] = S/n;
}
return (list_pz);
}")
list_pz <- unlist(PZ(n.simul,params,rvol,sim1,simulT))
pzero = mean(list_pz)
demi = qnorm(0.975)*sd(list_pz)/sqrt(n.simul)
return(list(p=pzero,demi.largeur=demi))
}
pzero.c(10,params)
pzero.c(10,params)
qnorm
help(qnorm)
params
params$V = 90000
params$T = 1.25
params$alpha = 0.8
params$sigma = 0.3
params
n.simul = 10
n.simul = 100
params
esp.t(n.simul,params)
n.simul = 10
pzero(n.simul,params)
params$T = 1.27
pzero(n.simul,params)
securite <- read.table("SecRoutiere0910.txt", header=TRUE)
setwd("~/Desktop/ISFA/Cours Perso/M1 Actuariat/Analyse des données et Clustering/TD/tdr1104")
securite <- read.table("SecRoutiere0910.txt", header=TRUE)
head(securite)
library(ade4)
acpSR <- dudi.pca(securite[,5:10],center=TRUE, scale=TRUE, scannf=FALSE, nf=2)
## 1 / La sécurité routière dans les départements français
# 1.
summary(acpSR)
barplot(acpSR$eig, las=1, names.arg=1:6) # graphe des valeurs propres
screeplot(acpSR) # graphe des valeurs propres, pas besoin de préciser le nom de l'ACP (indique directement le nbr de valeurs propres à retenir en noir)
# 2.
s.corcircle(acpSR$co, xax=1, yax=2) # Pas obliger de mettre xax et yax car par défaut c'est 1 et 2 mais si on doit représenter l'axe 2 et 3 ça devient utile
?s.corcircle
s.corcircle(acpSR$co, xax=1, yax=2, fullcircle=FALSE) # permet de réduire la zone à l'étude en question
# effet de taille = effet de proportionnalité
"Toutes les variables se projette de manière orthogonale sur l'axe 1 : ça veut dire que l'on a un effet de taille (size effect). ie un effet global. L'axe horizontal est l'axe d'accident de la route tout confondu.
Plus la variable est proche de 1, plus la variable intervient dans la relation
Axe vertical : specifité : le nombre de tué.
En ACP, on interprète jamais ce qu'il se passe au centre(erreur de projection)"
# 3.
s.label(acpSR$li) # rajout de la Corse => les numéros de départements ont été augmentés de 1 car cela affiche le numéro de la ligne
s.label(acpSR$li, label=securite$departement, clabel=0.5) # Paris est en haut => bcp d'accidents mais pas mortels, or bouches-du-rhone moins d'accidents mais plus mortels
# 4.
scatter(acpSR)
scatter(acpSR, posieig="topright")
# 5.
cor(acpSR$li[, 1], securite$population)
"La corrélation est positive, plus il y a du monde, plus il y a d'accident (la relation est positive car l'ACP a donné un résultat en négatif. Il faut regarder les données en fonction de l'ACP), la valeur est négative puisque sur le cercle de corrélation toutes les valeurs sont à gauche"
# 6.
par(mfrow=c(1,2))
s.label(acpSR$li,label=securite$numdep,clabel=0.75)
popu <- scale(securite$population,center=TRUE,scale=TRUE)
s.value(acpSR$li[,1:2],popu) # On voit bien qu'il y un biais lié à la population
## 2 / Le classement des vins par des juges
data(macon)
macon
dim(macon)
#Pour faire une typologie des juges, on utilise les juges en ligne dans une ACP centrée
tmacon <- t(macon)
head(tmacon)
apply(tmacon,1,sum)
apply(tmacon,2,sum)
acpMA <- dudi.pca(tmacon, center = TRUE, scale = FALSE) # Scale = false car on souhaite garder la variance
acpSR
acpSR$eig
summary(acpSR)
securite
head(securite,n=2L)
L
2L
dim(securite)
help(head)
table <- data.frame(a=eau1,b=eau2,c=eau3,d=eau4)
eau1 <- c(7,4.5,3)
eau2 <- c(4.5,9.5,2.5)
eau3 <- c(5.5,9.5,8.5)
eau4 <- c(0.5,5.5,2.5)
table <- data.frame(a=eau1,b=eau2,c=eau3,d=eau4)
table
table[1]
table[2]
Mg <- c(7,4.5,5.5,0.5)
Ca <- c(4.5,9.5,9.5,5.5)
NO3 <- c(3,2.5,8.5,2.5)
Mg <- c(7,4.5,5.5,0.5)
Ca <- c(4.5,9.5,9.5,5.5)
NO3 <- c(3,2.5,8.5,2.5)
table <- data.fram(x=Mg,y=Ca,z=NO3)
Mg <- c(7,4.5,5.5,0.5)
Ca <- c(4.5,9.5,9.5,5.5)
NO3 <- c(3,2.5,8.5,2.5)
table <- data.frame(x=Mg,y=Ca,z=NO3)
table
colnames(table) <- c("Mg","Ca","NO3")
table
D = dist(table,method="chebychev")
D = dist(table,method="tchebychev")
D = dist(table,method="Tchebychev")
D = dist(table,method="chebyshev")
D = dist_chebyshev(table)
help(dist)
D = dist(table,method="maximum")
D
hc <- hclust(D,method="average")
hc
plot(hc)
D
hc <- hclust(D,method="ward.D")
hc
plot(hc)
hc
hc$merge
merge(hc)
merge <- hc$merge
# Détermination de la matrice des valeurs de l'ultramétrique
n <- nrow(D)
ultra <- matrix(0, n, n)
nrow(D)
D
class(D)
as.matric(D)
as.matrix(D)
class(D)
nrow(as.matrix(D))
D <- as.matrix(D)
n <- nrow(D)
ultra <- matrix(0, n, n)
for (i in 1:n) {
for (j in 1:n) {
if (i < j) {
ultra[i,j] <- max(D[i,j], merge[which(merge[,1] %in% c(i,j)),3])
ultra[j,i] <- ultra[i,j]
}
}
}
merge
merge[2]
merge[3]
merge[3,3]
merge[3,2]
D <- as.matrix(D)
n <- nrow(D)
ultra <- matrix(0, n, n)
for (i in 1:n) {
for (j in 1:n) {
if (i < j) {
ultra[i,j] <- max(D[i,j], merge[which(merge[,1] %in% c(i,j)),2])
ultra[j,i] <- ultra[i,j]
}
}
}
ultra
D
install.packages("stats")
install.packages("stats")
install.packages("stats")
pchisq(10.61,df=2)
